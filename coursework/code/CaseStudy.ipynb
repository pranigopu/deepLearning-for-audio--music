{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e76faea3-7429-4acb-8a7e-a24fb836da85",
   "metadata": {},
   "source": [
    "# 4. APPLICATION OF MODEL TO SELECTED AUDIO FILE\n",
    "Necessary imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9db9cbd-c25d-4e09-a08f-1de34b5b53b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from .\\CombiningInferences.ipynb\n",
      "importing Jupyter notebook from .\\Functions.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "N = import_ipynb.NotebookLoader(path=['.'])\n",
    "N.load_module('CombiningInferences')\n",
    "from CombiningInferences import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fce1f5-0751-47eb-ab6f-e9422c98ded4",
   "metadata": {},
   "source": [
    "# Introducing the piece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21daf64-0fa7-4839-8fdd-0fdd8d5a14fc",
   "metadata": {},
   "source": [
    "Initialising classifier..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a116e7ef-15f0-4569-97d1-b9f54b3c6dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KeyAndTempoClassifier(audio_folders=['storage'])\n",
    "MY_TRACK = 'Ambient_Life.mp3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61898eba-a837-4f72-a97a-59a102082240",
   "metadata": {},
   "source": [
    "Listening the piece as a whole..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec517f7-db31-4bcb-b743-e11116fe426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.listen(MY_TRACK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a8923d-a698-4fdc-a4b6-febe0ba85d15",
   "metadata": {},
   "source": [
    "# Inference for the whole piece\n",
    "Obtaining inference for the whole track..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bff22f1f-899c-451b-9cde-20fcf82a562e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track</th>\n",
       "      <th>Predicted key</th>\n",
       "      <th>Predicted tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ambient_Life.mp3</td>\n",
       "      <td>C minor</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Track Predicted key  Predicted tempo\n",
       "0  Ambient_Life.mp3       C minor              125"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.get_inferences(MY_TRACK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982df632-820d-4312-a69b-193649198e70",
   "metadata": {},
   "source": [
    "# Inferences for each segment of the piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cccb92b9-2b55-4205-b368-ec26cd59368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, sr = classifier.load_track(MY_TRACK)\n",
    "\n",
    "#________________________\n",
    "# Short-time Fourier transform:\n",
    "stft = librosa.core.stft(signal, hop_length=classifier.audio_params_1['hop_length'], n_fft=classifier.audio_params_1['n_fft'])\n",
    "# Obtain the spectrogram:\n",
    "spectrogram = np.abs(stft)\n",
    "\n",
    "#________________________\n",
    "# Evening out irregularities in dimensions...\n",
    "\n",
    "# Pad spectrogram if necessary:\n",
    "if spectrogram.shape[1] < 4000:\n",
    "    spectrogram = np.pad(spectrogram, ((0, 0), (0, classifier.audio_params_1['n_frames']-spectrogram.shape[1])))\n",
    "# Truncate spectrogram if necessary\n",
    "spectrogram = spectrogram[:, :4000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20e80ba-bce6-4b41-b396-a11132695bba",
   "metadata": {},
   "source": [
    "Obtain the melspectrograms for the current audio file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3693cae8-2239-4f64-b7ee-f11aedd3fc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (40, 128, 200), (40, 100, 12)\n"
     ]
    }
   ],
   "source": [
    "# Get log-amplitude melspectrograms:\n",
    "log_spectrogram = librosa.amplitude_to_db(spectrogram)\n",
    "# Melspectrograms with log-scaled amplitudes:\n",
    "melspectrogram_1 = librosa.feature.melspectrogram(S=log_spectrogram,\n",
    "                                                  sr=classifier.audio_params_1['sr'],\n",
    "                                                  n_fft=classifier.audio_params_1['n_fft'],\n",
    "                                                  hop_length=classifier.audio_params_1['hop_length'],\n",
    "                                                  n_mels=classifier.audio_params_1['n_mels'])\n",
    "melspectrogram_2 = librosa.feature.melspectrogram(S=log_spectrogram,\n",
    "                                                  sr=classifier.audio_params_2['sr'],\n",
    "                                                  n_fft=classifier.audio_params_2['n_fft'],\n",
    "                                                  hop_length=classifier.audio_params_2['hop_length'],\n",
    "                                                  n_mels=classifier.audio_params_2['n_mels'])\n",
    "\n",
    "# Dividing each melspectrogram into 40 segments:\n",
    "'''\n",
    "NOTE:\n",
    "The division is done such that key classifying melspectrograms are 200 time stamps each,\n",
    "and tempo classifying melspectrograms are 100 time stamps each (to match the neural network architectures).\n",
    "'''\n",
    "\n",
    "melspectrograms_1, melspectrograms_2 = [], []\n",
    "\n",
    "for i in range(20):\n",
    "    k = 4000//20\n",
    "    melspectrograms_1 += [melspectrogram_1[:, i*k:(i+1)*k]]*2 # See comment below\n",
    "melspectrograms_1 = np.array(melspectrograms_1)\n",
    "\n",
    "'''\n",
    "Tempo classifier divides the audio file into twice as many segments as the key classifier.\n",
    "Hence, for each tempo-wise segment there are 2 key-wise segments.\n",
    "'''\n",
    "\n",
    "for i in range(40):\n",
    "    k = 4000//40\n",
    "    melspectrograms_2 += [np.transpose(melspectrogram_2[:, i*k:(i+1)*k])]\n",
    "melspectrograms_2 = np.array(melspectrograms_2)\n",
    "\n",
    "print(f'Shapes: {melspectrograms_1.shape}, {melspectrograms_2.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005c9e2e-b913-44be-b230-44498598bc52",
   "metadata": {},
   "source": [
    "Getting the inferences for each segment of the current file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed471cca-7358-4677-ad67-e50f0d1bf11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_preds, tempo_preds = classifier.get_inferences_for_melspectrograms(melspectrograms_1, melspectrograms_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec9844f-28f8-45af-930f-ad42ec6eae7b",
   "metadata": {},
   "source": [
    "Presenting as dataframe..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf8b8abb-dace-47e1-aab6-1bd9671305e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Segment</th>\n",
       "      <th>Key predictions</th>\n",
       "      <th>Tempo predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>C minor</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>C minor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>F major</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>F major</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>C minor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>C minor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>C minor</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>C minor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>F major</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>F major</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Segment Key predictions  Tempo predictions\n",
       "0        1         C minor                125\n",
       "1        2         C minor                  0\n",
       "2        3         F major                110\n",
       "3        4         F major                  0\n",
       "4        5         C minor                  0\n",
       "5        6         C minor                  0\n",
       "6        7         C minor                120\n",
       "7        8         C minor                  0\n",
       "8        9         F major                  0\n",
       "9       10         F major                  0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data={'Segment': range(1, 41), 'Key predictions':key_preds, 'Tempo predictions':tempo_preds})[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d70b7ba-e918-4a09-a744-bda7b140f981",
   "metadata": {},
   "source": [
    "Listening to each segment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f79b0f8-45e4-4182-aaaf-32d89f06f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to facilitate outputs:\n",
    "def list_to_segment(i):\n",
    "    i = i - 1\n",
    "    k = len(signal)//40\n",
    "    classifier.listen_to_signal(signal[i*k:(i+1)*k], sr=classifier.audio_params_1['sr'])\n",
    "\n",
    "#================================================\n",
    "# Inputs:\n",
    "n = int(input('Enter segment: '))\n",
    "try:\n",
    "    list_to_segment(n)\n",
    "except:\n",
    "    print('Invalid input')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fc3993-3c41-4243-9303-c560f7750ccc",
   "metadata": {},
   "source": [
    "We can compare the pitch using:\n",
    "\n",
    "https://www.szynalski.com/tone-generator/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
